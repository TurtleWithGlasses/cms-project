# CMS Project — Monitoring Stack
#
# Launches the full observability stack independently of the application.
# Use alongside docker-compose.yml (dev) or docker-compose.prod.yml (prod).
#
# Usage:
#   docker compose -f docker-compose.yml -f docker-compose.monitoring.yml up -d
#
# Or standalone (metrics scraped from the host network):
#   docker compose -f docker-compose.monitoring.yml up -d
#
# Required environment variables (copy from .env.example):
#   GRAFANA_USER, GRAFANA_PASSWORD
#   POSTGRES_USER, POSTGRES_PASSWORD
#   SLACK_WEBHOOK_URL   (optional — for Alertmanager Slack notifications)

name: cms-monitoring

services:
  # ─── Prometheus ─────────────────────────────────────────────────────────────
  prometheus:
    image: prom/prometheus:v2.54.0
    container_name: cms-prometheus
    restart: unless-stopped
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --storage.tsdb.retention.time=15d
      - --web.enable-lifecycle          # POST /-/reload to hot-reload config
      - --web.enable-admin-api
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - monitoring
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 15s
      timeout: 5s
      retries: 3

  # ─── Alertmanager ────────────────────────────────────────────────────────────
  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: cms-alertmanager
    restart: unless-stopped
    command:
      - --config.file=/etc/alertmanager/alertmanager.yml
      - --storage.path=/alertmanager
      - --web.listen-address=:9093
    environment:
      SLACK_WEBHOOK_URL: ${SLACK_WEBHOOK_URL:-}
    volumes:
      - ./monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    ports:
      - "9093:9093"
    networks:
      - monitoring
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9093/-/healthy"]
      interval: 15s
      timeout: 5s
      retries: 3

  # ─── Grafana ─────────────────────────────────────────────────────────────────
  grafana:
    image: grafana/grafana:11.3.0
    container_name: cms-grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_SERVER_ROOT_URL: "%(protocol)s://%(domain)s:%(http_port)s/grafana/"
      GF_ANALYTICS_REPORTING_ENABLED: "false"
      GF_FEATURE_TOGGLES_ENABLE: "publicDashboards"
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana_data:/var/lib/grafana
    ports:
      - "3001:3000"    # 3001 to avoid conflict with the React frontend on 3000
    networks:
      - monitoring
    depends_on:
      prometheus:
        condition: service_healthy
      loki:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 15s
      timeout: 5s
      retries: 5

  # ─── Loki ────────────────────────────────────────────────────────────────────
  loki:
    image: grafana/loki:3.2.0
    container_name: cms-loki
    restart: unless-stopped
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./monitoring/loki/loki-config.yaml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    ports:
      - "3100:3100"
    networks:
      - monitoring
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3100/ready"]
      interval: 15s
      timeout: 5s
      retries: 5

  # ─── Promtail ────────────────────────────────────────────────────────────────
  promtail:
    image: grafana/promtail:3.2.0
    container_name: cms-promtail
    restart: unless-stopped
    command: -config.file=/etc/promtail/config.yaml
    volumes:
      - ./monitoring/promtail/promtail-config.yaml:/etc/promtail/config.yaml:ro
      - /var/log:/var/log:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - monitoring
    depends_on:
      loki:
        condition: service_healthy

  # ─── PostgreSQL Exporter ─────────────────────────────────────────────────────
  postgres-exporter:
    image: quay.io/prometheuscommunity/postgres-exporter:v0.15.0
    container_name: cms-postgres-exporter
    restart: unless-stopped
    environment:
      DATA_SOURCE_NAME: >-
        postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-postgres}@db:5432/postgres?sslmode=disable
    ports:
      - "9187:9187"
    networks:
      - monitoring
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9187/metrics"]
      interval: 15s
      timeout: 5s
      retries: 3

  # ─── Redis Exporter ──────────────────────────────────────────────────────────
  redis-exporter:
    image: oliver006/redis_exporter:v1.65.0
    container_name: cms-redis-exporter
    restart: unless-stopped
    environment:
      REDIS_ADDR: redis://redis:6379
      REDIS_PASSWORD: ${REDIS_PASSWORD:-}
    ports:
      - "9121:9121"
    networks:
      - monitoring
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9121/metrics"]
      interval: 15s
      timeout: 5s
      retries: 3

networks:
  monitoring:
    name: cms_monitoring
    driver: bridge

volumes:
  prometheus_data:
    name: cms_prometheus_data
  alertmanager_data:
    name: cms_alertmanager_data
  grafana_data:
    name: cms_grafana_data
  loki_data:
    name: cms_loki_data
